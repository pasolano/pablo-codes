# Responses for 5 February 2021

## In Laurence Maroneyâ€™s video, What is ML, he compares traditional programming with machine learning and argues that the main difference between the two is a reorientation of the rules, data and answers. According to Maroney, what is the difference between traditional programming and machine learning?

In traditional programming, programmers write code that establishes rules regarding how data that is passed to it should be handled. Then, once said data is passed through those rules, it becomes the answer to whatever question the programmer had (if they did their job right, that is).
In machine learning, the programmer instead collects large amounts of data, and assigns answers to that data through labelling. For example, one could label a dataset that includes heart rates and breathing patterns with whether or not that person was doing a form of exercise. The code would then look at this data and learn how to predict the answer based on what the input is, eventually inferring the rules on its own.
In traditional programming, the programmer provides rules which change data to produce results. In machine learning, the programmer provides data and answers which allows the code to produce the rules.

## With the first basic script that Maroney used to predict a value output from the model he estimated (he initially started with 10 that predicted ~31. Modify the predict function to produce the output for the value 7. Do this twice and provide both answers. Are they the same? Are they different? Why is this so?

When I modified the script to predict the value of 7, I got `12.986599` on the first run and `12.992164` on the second. These runs are similar but different. Both runs guess that the value is likely to be close to being linear, but they don't know that for sure so they both only get close to that value. They are different because they handled the possibility that the the relationship might not be linear slightly differently. In other words, the loss calculations from their 500 guesses were different, so they also compensated for those losses differently. This led to them having _slightly_ different learned rules.

## Using the script you produced to predict housing price, take the provided six houses from Mathews, Virginia and train a neural net model that estimates the relationship between them. Based on this model, which of the six homes present a good deal? Which one is the worst deal? Justify your answer

Based on a model that only compares the number of bedrooms to the price of the house on the posted listing, the "Hudgins," "Mobjack," and "New Point Comfort" houses are all considered to be good deals by the neural network since it predicted these houses should be worth more than they are being sold for based on the prices of the other houses in the dataset. The worst deal is the "Mathews" house, which is being sold for ~$112 dollars more than it's worth, since the model predicted that the house should be worth $112 less than it is being listed at. Of course, property prices are more complicated than just the number of rooms, but it is interesting to think of the kind of predictions a more advanced model could produce.